<?xml version='1.0' encoding='UTF-8'?>
<project>
  <actions/>
  <description>I&apos;ll do deployment of jars on the spark jobserver on production </description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <hudson.plugins.buildblocker.BuildBlockerProperty plugin="build-blocker-plugin@1.6">
      <useBuildBlocker>false</useBuildBlocker>
    </hudson.plugins.buildblocker.BuildBlockerProperty>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.StringParameterDefinition>
          <name>IDENTIFIER</name>
          <description></description>
          <defaultValue>0.1</defaultValue>
        </hudson.model.StringParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
  </properties>
  <scm class="hudson.scm.NullSCM"/>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers/>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>#!/bin/bash

releaseIdentifier=Release_Spark-Jobserver-Prod_${IDENTIFIER}

#scp /release/${releaseIdentifier}/BigParser-assembly-1.0.jar prod-hadoop-jobserver.bigparser.com:/tmp 
#scp /release/${releaseIdentifier}/dev_local.conf prod-hadoop-jobserver.bigparser.com:/home/hadoop/job-server/local.conf
#ssh prod-hadoop-jobserver.bigparser.com &quot;curl --data-binary @/tmp/BigParser-assembly-1.0.jar localhost:8090/jars/bigparser&quot;
#ssh prod-hadoop-jobserver.bigparser.com &quot;cp /tmp/BigParser-assembly-1.0.jar /home/hadoop/spark/user-jars/&quot;
#ssh prod-hadoop-jobserver.bigparser.com &quot;rm -rf /tmp/BigParser-assembly-1.0.jar&quot;
#ssh -o StrictHostKeyChecking=no hadoop@$SERVER &quot;curl -X DELETE &apos;localhost:8090/contexts/dataparsing-context&apos;&quot;
#ssh prod-hadoop-jobserver.bigparser.com &quot;/home/hadoop/job-server/server_stop.sh &amp;&amp; /home/hadoop/job-server/server_start.sh &amp;&amp; sleep 1m&quot;
#ssh -o StrictHostKeyChecking=no hadoop@$SERVER &quot;curl -d &apos;&apos; &apos;localhost:8090/contexts/dataparsing-context?num-cpu-cores=4&amp;memory-per-node=512m&apos;&quot;

</command>
    </hudson.tasks.Shell>
  </builders>
  <publishers/>
  <buildWrappers/>
</project>